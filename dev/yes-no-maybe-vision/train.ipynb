{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.7.1+cu126 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhilton\u001b[0m (\u001b[33mwandb\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sky/sky_workdir/dev/yes-no-maybe-vision/wandb/run-20251022_222913-009</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wandb/yes-no-maybe-vision/runs/009' target=\"_blank\">009</a></strong> to <a href='https://wandb.ai/wandb/yes-no-maybe-vision' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb/yes-no-maybe-vision' target=\"_blank\">https://wandb.ai/wandb/yes-no-maybe-vision</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb/yes-no-maybe-vision/runs/009' target=\"_blank\">https://wandb.ai/wandb/yes-no-maybe-vision/runs/009</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-22 22:29:16 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.7.1+cu126 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n",
      "/home/sky/sky_workdir/src/art/__init__.py:10: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  import unsloth  # type: ignore # noqa: F401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-22 22:29:22 [__init__.py:235] Automatically detected platform cuda.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.10.8: Fast Qwen3_Vl patching. Transformers: 4.57.1. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA H200. Num GPUs = 1. Max memory: 139.811 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unsloth_zoo.log: Unsloth: Patching vLLM\n",
      "WARNING:unsloth_zoo.log: Unsloth: Switching from Unsloth dynamic quant to normal quant since\n",
      "we do not yet support fast inference for unsloth/qwen3-vl-8b-instruct-unsloth-bnb-4bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-22 22:29:34 [vllm_utils.py:694] Unsloth: Patching vLLM v1 graph capture\n",
      "INFO 10-22 22:29:34 [vllm_utils.py:722] Unsloth: Patching vLLM v0 graph capture\n",
      "Unsloth: Vision model detected, setting approx_max_num_seqs to 1\n",
      "Unsloth: vLLM loading unsloth/qwen3-vl-8b-instruct-bnb-4bit with actual GPU utilization = 78.66%\n",
      "Unsloth: Your GPU has CUDA compute capability 9.0 with VRAM = 139.81 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 1.\n",
      "Unsloth: vLLM's KV Cache can use up to 103.57 GB. Also swap space = 6 GB.\n",
      "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-22 22:29:41 [config.py:1604] Using max model len 32768\n",
      "WARNING 10-22 22:29:41 [arg_utils.py:1511] --enable-prefix-caching is not supported for multimodal models in V0 and has been disabled.\n",
      "INFO 10-22 22:29:41 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=32768.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['embed_tokens', 'embedding', 'lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'router', 'visual', 'vision_tower'], 'llm_int8_threshold': 6.0}\n",
      "INFO 10-22 22:29:41 [llm_engine.py:228] Initializing a V0 LLM engine (v0.10.0) with config: model='unsloth/qwen3-vl-8b-instruct-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen3-vl-8b-instruct-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen3-vl-8b-instruct-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":32,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"max_capture_size\":1,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 10-22 22:29:46 [cuda.py:398] Using Flash Attention backend.\n",
      "INFO 10-22 22:29:46 [parallel_state.py:1102] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 10-22 22:29:46 [model_runner.py:1083] Starting to load model unsloth/qwen3-vl-8b-instruct-bnb-4bit...\n",
      "WARNING 10-22 22:29:46 [utils.py:185] Qwen3VLForConditionalGeneration has no vLLM implementation, falling back to Transformers implementation. Some features may not be supported and performance may not be optimal.\n",
      "INFO 10-22 22:29:46 [transformers.py:421] Using Transformers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "vLLM currently does not support BNB quantization for",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/unsloth_zoo/vllm_utils.py:1763\u001b[0m, in \u001b[0;36mload_vllm\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_async:\n\u001b[0;32m-> 1763\u001b[0m     llm \u001b[38;5;241m=\u001b[39m AsyncLLMEngine\u001b[38;5;241m.\u001b[39mfrom_engine_args(AsyncEngineArgs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_args))\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m use_engine:\n",
      "File \u001b[0;32m~/sky_workdir/src/art/unsloth/state.py:74\u001b[0m, in \u001b[0;36m_from_engine_args\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_engine_args\u001b[39m(\n\u001b[1;32m     72\u001b[0m     engine_args: AsyncEngineArgs, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     73\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncLLMEngine:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_engine_args(\n\u001b[1;32m     75\u001b[0m         replace(engine_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     76\u001b[0m     )\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py:653\u001b[0m, in \u001b[0;36mfrom_engine_args\u001b[0;34m()\u001b[0m\n\u001b[1;32m    651\u001b[0m     async_engine_cls \u001b[38;5;241m=\u001b[39m V1AsyncLLMEngine\n\u001b[0;32m--> 653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m async_engine_cls\u001b[38;5;241m.\u001b[39mfrom_vllm_config(\n\u001b[1;32m    654\u001b[0m     vllm_config\u001b[38;5;241m=\u001b[39mvllm_config,\n\u001b[1;32m    655\u001b[0m     start_engine_loop\u001b[38;5;241m=\u001b[39mstart_engine_loop,\n\u001b[1;32m    656\u001b[0m     usage_context\u001b[38;5;241m=\u001b[39musage_context,\n\u001b[1;32m    657\u001b[0m     stat_loggers\u001b[38;5;241m=\u001b[39mstat_loggers,\n\u001b[1;32m    658\u001b[0m     disable_log_stats\u001b[38;5;241m=\u001b[39mengine_args\u001b[38;5;241m.\u001b[39mdisable_log_stats,\n\u001b[1;32m    659\u001b[0m     disable_log_requests\u001b[38;5;241m=\u001b[39mengine_args\u001b[38;5;241m.\u001b[39mdisable_log_requests,\n\u001b[1;32m    660\u001b[0m )\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py:626\u001b[0m, in \u001b[0;36mfrom_vllm_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an AsyncLLMEngine from the EngineArgs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    627\u001b[0m     vllm_config\u001b[38;5;241m=\u001b[39mvllm_config,\n\u001b[1;32m    628\u001b[0m     executor_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_executor_cls(vllm_config),\n\u001b[1;32m    629\u001b[0m     start_engine_loop\u001b[38;5;241m=\u001b[39mstart_engine_loop,\n\u001b[1;32m    630\u001b[0m     log_requests\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_log_requests,\n\u001b[1;32m    631\u001b[0m     log_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_log_stats,\n\u001b[1;32m    632\u001b[0m     usage_context\u001b[38;5;241m=\u001b[39musage_context,\n\u001b[1;32m    633\u001b[0m     stat_loggers\u001b[38;5;241m=\u001b[39mstat_loggers,\n\u001b[1;32m    634\u001b[0m )\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py:581\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_requests \u001b[38;5;241m=\u001b[39m log_requests\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine_class(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# This ensures quick processing of request outputs\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# so the append to asyncio queues is not delayed,\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# especially for multi-step.\u001b[39;00m\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/engine/async_llm_engine.py:265\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/engine/llm_engine.py:263\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_preprocessor \u001b[38;5;241m=\u001b[39m InputPreprocessor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m    260\u001b[0m                                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m    261\u001b[0m                                             mm_registry)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m executor_class(vllm_config\u001b[38;5;241m=\u001b[39mvllm_config)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mrunner_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/executor/executor_base.py:53\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;241m=\u001b[39m vllm_config\u001b[38;5;241m.\u001b[39mobservability_config\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_executor()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sleeping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py:49\u001b[0m, in \u001b[0;36m_init_executor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollective_rpc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollective_rpc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py:58\u001b[0m, in \u001b[0;36mcollective_rpc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 58\u001b[0m answer \u001b[38;5;241m=\u001b[39m run_method(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker, method, args, kwargs)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/utils/__init__.py:2985\u001b[0m, in \u001b[0;36mrun_method\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2984\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/worker/worker.py:211\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_runner\u001b[38;5;241m.\u001b[39mload_model()\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/worker/model_runner.py:1086\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1085\u001b[0m time_before_load \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m-> 1086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m get_model(vllm_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvllm_config)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_config:\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py:59\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m vllm_config\u001b[38;5;241m.\u001b[39mmodel_config\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mload_model(vllm_config\u001b[38;5;241m=\u001b[39mvllm_config,\n\u001b[1;32m     60\u001b[0m                          model_config\u001b[38;5;241m=\u001b[39mmodel_config)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/base_loader.py:49\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Quantization does not happen in `load_weights` but after it\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_weights(model, model_config)\n\u001b[1;32m     50\u001b[0m process_weights_after_loading(model, model_config, target_device)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/bitsandbytes_loader.py:731\u001b[0m, in \u001b[0;36mload_weights\u001b[0;34m()\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_model_compatibility(model, model_config)\n\u001b[0;32m--> 731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_loader_state(model, model_config)\n\u001b[1;32m    733\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading weights with BitsAndBytes quantization. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMay take a while ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/bitsandbytes_loader.py:524\u001b[0m, in \u001b[0;36m_initialize_loader_state\u001b[0;34m()\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_mapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m name: hf_to_vllm_mapper\u001b[38;5;241m.\u001b[39m_map_name(name)\n\u001b[0;32m--> 524\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bnb_target_modules(model)\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classify_module_sharding(model)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/bitsandbytes_loader.py:441\u001b[0m, in \u001b[0;36m_get_bnb_target_modules\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_modules\u001b[38;5;241m.\u001b[39mappend(rep_name)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_modules\n\u001b[1;32m    442\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvLLM currently does not support BNB quantization for\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: vLLM currently does not support BNB quantization for",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m backend \u001b[38;5;241m=\u001b[39m LocalBackend()\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m art\u001b[38;5;241m.\u001b[39mTrainableModel(\n\u001b[1;32m     12\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m009\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes-no-maybe-vision\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     base_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen3-VL-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m model\u001b[38;5;241m.\u001b[39mregister(backend)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrollout\u001b[39m(client: openai\u001b[38;5;241m.\u001b[39mAsyncOpenAI, image_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m art\u001b[38;5;241m.\u001b[39mTrajectory:\n\u001b[1;32m     20\u001b[0m     messages: art\u001b[38;5;241m.\u001b[39mMessages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m         {\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: image_path}}],\n\u001b[1;32m     24\u001b[0m         }\n\u001b[1;32m     25\u001b[0m     ]\n",
      "File \u001b[0;32m~/sky_workdir/src/art/model.py:335\u001b[0m, in \u001b[0;36mTrainableModel.register\u001b[0;34m(self, backend, _openai_client_config)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mregister\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    331\u001b[0m     backend: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m     _openai_client_config: dev\u001b[38;5;241m.\u001b[39mOpenAIServerConfig \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mregister(backend)\n\u001b[0;32m--> 335\u001b[0m     base_url, api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m backend\u001b[38;5;241m.\u001b[39m_prepare_backend_for_training(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m, _openai_client_config\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Populate the top-level inference fields so that the rest of the\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# code (and any user code) can create an OpenAI client immediately.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_base_url \u001b[38;5;241m=\u001b[39m base_url\n",
      "File \u001b[0;32m~/sky_workdir/src/art/local/backend.py:282\u001b[0m, in \u001b[0;36mLocalBackend._prepare_backend_for_training\u001b[0;34m(self, model, config)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_prepare_backend_for_training\u001b[39m(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    278\u001b[0m     model: TrainableModel,\n\u001b[1;32m    279\u001b[0m     config: dev\u001b[38;5;241m.\u001b[39mOpenAIServerConfig \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    281\u001b[0m     service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_service(model)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m service\u001b[38;5;241m.\u001b[39mstart_openai_server(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m    283\u001b[0m     server_args \u001b[38;5;241m=\u001b[39m (config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserver_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m    285\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserver_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserver_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m8000\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/sky_workdir/src/mp_actors/traceback.py:26\u001b[0m, in \u001b[0;36mstreamline_tracebacks.<locals>.decorator.<locals>.async_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(streamlined_traceback())\n",
      "File \u001b[0;32m~/sky_workdir/src/art/unsloth/service.py:60\u001b[0m, in \u001b[0;36mstart_openai_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     lora_path \u001b[38;5;241m=\u001b[39m get_step_checkpoint_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     59\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(lora_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39msave_model(lora_path)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_openai_server()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_openai_server_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m openai_server_task(\n\u001b[1;32m     63\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mvllm\u001b[38;5;241m.\u001b[39masync_engine,\n\u001b[1;32m     64\u001b[0m     config\u001b[38;5;241m=\u001b[39mdev\u001b[38;5;241m.\u001b[39mget_openai_server_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     ),\n\u001b[1;32m     71\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36m__get__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/sky_workdir/src/art/unsloth/service.py:45\u001b[0m, in \u001b[0;36mstate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelState\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelState\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ModelState(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/sky_workdir/src/art/unsloth/state.py:82\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_engine_args(\n\u001b[1;32m     75\u001b[0m         replace(engine_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     78\u001b[0m AsyncLLMEngine\u001b[38;5;241m.\u001b[39mfrom_engine_args \u001b[38;5;241m=\u001b[39m _from_engine_args\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mtuple\u001b[39m[CausallLM, PreTrainedTokenizerBase],\n\u001b[0;32m---> 82\u001b[0m     unsloth\u001b[38;5;241m.\u001b[39mFastLanguageModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})),\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     84\u001b[0m AsyncLLMEngine\u001b[38;5;241m.\u001b[39mfrom_engine_args \u001b[38;5;241m=\u001b[39m from_engine_args\n\u001b[1;32m     85\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache \u001b[38;5;241m=\u001b[39m empty_cache\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/unsloth/models/loader.py:431\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m()\u001b[0m\n\u001b[1;32m    414\u001b[0m     dispatch_model \u001b[38;5;241m=\u001b[39m FastQwen3Model \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m FastQwen3MoeModel\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# elif model_type == \"falcon_h1\":\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m#     dispatch_model = FastFalconH1Model\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m#     if not SUPPORTS_FALCON_H1:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m#     dispatch_model = FastGraniteModel\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FastModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    432\u001b[0m         model_name                 \u001b[38;5;241m=\u001b[39m old_model_name,\n\u001b[1;32m    433\u001b[0m         max_seq_length             \u001b[38;5;241m=\u001b[39m max_seq_length,\n\u001b[1;32m    434\u001b[0m         dtype                      \u001b[38;5;241m=\u001b[39m dtype,\n\u001b[1;32m    435\u001b[0m         load_in_4bit               \u001b[38;5;241m=\u001b[39m load_in_4bit,\n\u001b[1;32m    436\u001b[0m         load_in_8bit               \u001b[38;5;241m=\u001b[39m load_in_8bit,\n\u001b[1;32m    437\u001b[0m         load_in_16bit              \u001b[38;5;241m=\u001b[39m load_in_16bit,\n\u001b[1;32m    438\u001b[0m         full_finetuning            \u001b[38;5;241m=\u001b[39m full_finetuning,\n\u001b[1;32m    439\u001b[0m         token                      \u001b[38;5;241m=\u001b[39m token,\n\u001b[1;32m    440\u001b[0m         device_map                 \u001b[38;5;241m=\u001b[39m device_map,\n\u001b[1;32m    441\u001b[0m         rope_scaling               \u001b[38;5;241m=\u001b[39m rope_scaling, \u001b[38;5;66;03m# [TODO] No effect\u001b[39;00m\n\u001b[1;32m    442\u001b[0m         fix_tokenizer              \u001b[38;5;241m=\u001b[39m fix_tokenizer, \u001b[38;5;66;03m# [TODO] No effect\u001b[39;00m\n\u001b[1;32m    443\u001b[0m         trust_remote_code          \u001b[38;5;241m=\u001b[39m trust_remote_code,\n\u001b[1;32m    444\u001b[0m         use_gradient_checkpointing \u001b[38;5;241m=\u001b[39m use_gradient_checkpointing,\n\u001b[1;32m    445\u001b[0m         resize_model_vocab         \u001b[38;5;241m=\u001b[39m resize_model_vocab, \u001b[38;5;66;03m# [TODO] No effect\u001b[39;00m\n\u001b[1;32m    446\u001b[0m         revision                   \u001b[38;5;241m=\u001b[39m revision,\n\u001b[1;32m    447\u001b[0m         return_logits              \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Return logits\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         fullgraph                  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# No graph breaks\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         use_exact_model_name       \u001b[38;5;241m=\u001b[39m use_exact_model_name,\n\u001b[1;32m    450\u001b[0m         offload_embedding          \u001b[38;5;241m=\u001b[39m offload_embedding,\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m         \u001b[38;5;66;03m# Pass vLLM/inference parameters\u001b[39;00m\n\u001b[1;32m    453\u001b[0m         fast_inference             \u001b[38;5;241m=\u001b[39m fast_inference,\n\u001b[1;32m    454\u001b[0m         gpu_memory_utilization     \u001b[38;5;241m=\u001b[39m gpu_memory_utilization,\n\u001b[1;32m    455\u001b[0m         float8_kv_cache            \u001b[38;5;241m=\u001b[39m float8_kv_cache,\n\u001b[1;32m    456\u001b[0m         random_state               \u001b[38;5;241m=\u001b[39m random_state,\n\u001b[1;32m    457\u001b[0m         max_lora_rank              \u001b[38;5;241m=\u001b[39m max_lora_rank,\n\u001b[1;32m    458\u001b[0m         disable_log_stats          \u001b[38;5;241m=\u001b[39m disable_log_stats,\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    461\u001b[0m     )\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gradient_checkpointing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/unsloth/models/loader.py:988\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m()\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     auto_model \u001b[38;5;241m=\u001b[39m AutoModelForVision2Seq \u001b[38;5;28;01mif\u001b[39;00m is_vlm \u001b[38;5;28;01melse\u001b[39;00m AutoModelForCausalLM\n\u001b[0;32m--> 988\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m FastBaseModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    989\u001b[0m     model_name        \u001b[38;5;241m=\u001b[39m model_name,\n\u001b[1;32m    990\u001b[0m     max_seq_length    \u001b[38;5;241m=\u001b[39m max_seq_length,\n\u001b[1;32m    991\u001b[0m     dtype             \u001b[38;5;241m=\u001b[39m _get_dtype(dtype),\n\u001b[1;32m    992\u001b[0m     load_in_4bit      \u001b[38;5;241m=\u001b[39m load_in_4bit,\n\u001b[1;32m    993\u001b[0m     load_in_8bit      \u001b[38;5;241m=\u001b[39m load_in_8bit,\n\u001b[1;32m    994\u001b[0m     load_in_16bit     \u001b[38;5;241m=\u001b[39m load_in_16bit,\n\u001b[1;32m    995\u001b[0m     full_finetuning   \u001b[38;5;241m=\u001b[39m full_finetuning,\n\u001b[1;32m    996\u001b[0m     token             \u001b[38;5;241m=\u001b[39m token,\n\u001b[1;32m    997\u001b[0m     device_map        \u001b[38;5;241m=\u001b[39m device_map,\n\u001b[1;32m    998\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m trust_remote_code,\n\u001b[1;32m    999\u001b[0m     revision          \u001b[38;5;241m=\u001b[39m revision \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_peft \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1000\u001b[0m     model_types       \u001b[38;5;241m=\u001b[39m model_types,\n\u001b[1;32m   1001\u001b[0m     tokenizer_name    \u001b[38;5;241m=\u001b[39m tokenizer_name,\n\u001b[1;32m   1002\u001b[0m     auto_model        \u001b[38;5;241m=\u001b[39m auto_model,\n\u001b[1;32m   1003\u001b[0m     use_gradient_checkpointing \u001b[38;5;241m=\u001b[39m use_gradient_checkpointing,\n\u001b[1;32m   1004\u001b[0m     supports_sdpa     \u001b[38;5;241m=\u001b[39m supports_sdpa,\n\u001b[1;32m   1005\u001b[0m     whisper_language  \u001b[38;5;241m=\u001b[39m whisper_language,\n\u001b[1;32m   1006\u001b[0m     whisper_task      \u001b[38;5;241m=\u001b[39m whisper_task,\n\u001b[1;32m   1007\u001b[0m     auto_config       \u001b[38;5;241m=\u001b[39m model_config,\n\u001b[1;32m   1008\u001b[0m     offload_embedding \u001b[38;5;241m=\u001b[39m offload_embedding,\n\u001b[1;32m   1009\u001b[0m \n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Pass vLLM/inference parameters\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     fast_inference         \u001b[38;5;241m=\u001b[39m fast_inference,\n\u001b[1;32m   1012\u001b[0m     gpu_memory_utilization \u001b[38;5;241m=\u001b[39m gpu_memory_utilization,\n\u001b[1;32m   1013\u001b[0m     float8_kv_cache        \u001b[38;5;241m=\u001b[39m float8_kv_cache,\n\u001b[1;32m   1014\u001b[0m     random_state           \u001b[38;5;241m=\u001b[39m random_state,\n\u001b[1;32m   1015\u001b[0m     max_lora_rank          \u001b[38;5;241m=\u001b[39m max_lora_rank,\n\u001b[1;32m   1016\u001b[0m     disable_log_stats      \u001b[38;5;241m=\u001b[39m disable_log_stats,\n\u001b[1;32m   1017\u001b[0m \n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1022\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(resize_model_vocab)\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/unsloth/models/vision.py:628\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m()\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# Load vLLM first\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m llm \u001b[38;5;241m=\u001b[39m load_vllm(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mload_vllm_kwargs)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# Convert to HF format\u001b[39;00m\n\u001b[1;32m    631\u001b[0m _, quant_state_dict \u001b[38;5;241m=\u001b[39m get_vllm_state_dict(\n\u001b[1;32m    632\u001b[0m     llm,\n\u001b[1;32m    633\u001b[0m     config \u001b[38;5;241m=\u001b[39m model_config,\n\u001b[1;32m    634\u001b[0m     is_vision_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    635\u001b[0m )\n",
      "File \u001b[0;32m~/sky_workdir/.venv/lib/python3.10/site-packages/unsloth_zoo/vllm_utils.py:1792\u001b[0m, in \u001b[0;36mload_vllm\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m   1788\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Retrying vLLM to process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapprox_max_num_seqs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sequences and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_num_batched_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens in tandem.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1789\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1790\u001b[0m             )\n\u001b[1;32m   1791\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1792\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error)\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: vLLM currently does not support BNB quantization for"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from generate_images import generate_yes_no_maybe_prompts, save_prompt_images\n",
    "\n",
    "import art\n",
    "from art.local import LocalBackend\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "backend = LocalBackend()\n",
    "model = art.TrainableModel(\n",
    "    name=\"009\",\n",
    "    project=\"yes-no-maybe-vision\",\n",
    "    base_model=\"Qwen/Qwen3-VL-8B-Instruct\",\n",
    ")\n",
    "await model.register(backend)\n",
    "\n",
    "\n",
    "async def rollout(client: openai.AsyncOpenAI, image_path: str) -> art.Trajectory:\n",
    "    messages: art.Messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": image_path}}],\n",
    "        }\n",
    "    ]\n",
    "    chat_completion = await client.chat.completions.create(\n",
    "        model=model.name, messages=messages, max_tokens=100, timeout=100\n",
    "    )\n",
    "    choice = chat_completion.choices[0]\n",
    "    content = choice.message.content\n",
    "    assert isinstance(content, str)\n",
    "    if content == \"yes\":\n",
    "        reward = 0.5\n",
    "    elif content == \"no\":\n",
    "        reward = 0.75\n",
    "    elif content == \"maybe\":\n",
    "        reward = 1.0\n",
    "    else:\n",
    "        reward = 0.0\n",
    "    return art.Trajectory(messages_and_choices=[*messages, choice], reward=reward)\n",
    "\n",
    "\n",
    "image_paths = save_prompt_images(\n",
    "    generate_yes_no_maybe_prompts(),\n",
    "    \"/tmp/yes-no-maybe-vision/images\",\n",
    "    image_size=(256, 256),\n",
    "    margin_px=16,\n",
    "    font_path=None,\n",
    ")\n",
    "\n",
    "\n",
    "openai_client = model.openai_client()\n",
    "for _ in range(await model.get_step(), 1_000):\n",
    "    train_groups = await art.gather_trajectory_groups(\n",
    "        (\n",
    "            art.TrajectoryGroup(\n",
    "                rollout(openai_client, image_path.as_uri()) for _ in range(32)\n",
    "            )\n",
    "            for image_path in image_paths\n",
    "        )\n",
    "    )\n",
    "    await model.train(\n",
    "        train_groups,\n",
    "        config=art.TrainConfig(learning_rate=1e-4),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
