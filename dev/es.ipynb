{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import art\n",
    "\n",
    "# from art.local import LocalBackend\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-16c4386e-d10f-4d6c-a237-75b4c8813c56', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! It's nice to meet you. How can I assist you today?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1759795924, model='Qwen/Qwen2.5-14B-Instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=33, total_tokens=50, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, kv_transfer_params=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "openai_client = openai.AsyncOpenAI(\n",
    "    api_key=os.getenv(\"WANDB_API_KEY\"),\n",
    "    base_url=\"https://api.inference.coreweave.com/v1\",\n",
    ")\n",
    "await openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}],\n",
    "    model=\"Qwen/Qwen2.5-14B-Instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhilton\u001b[0m (\u001b[33mwandb\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/art/dev/wandb/run-20251007_001206-i1z39qki</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wandb/es/runs/i1z39qki' target=\"_blank\">northern-paper-4</a></strong> to <a href='https://wandb.ai/wandb/es' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wandb/es' target=\"_blank\">https://wandb.ai/wandb/es</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wandb/es/runs/i1z39qki' target=\"_blank\">https://wandb.ai/wandb/es/runs/i1z39qki</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1100204/2800122005.py:4: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  import unsloth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-07 00:12:13 [__init__.py:235] Automatically detected platform cuda.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.9.6: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.10.0.\n",
      "   \\\\   /|    NVIDIA H200. Num GPUs = 2. Max memory: 139.811 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd9218b579c4b518569568795240f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "from typing import cast\n",
    "\n",
    "import peft\n",
    "import unsloth\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.utils.dummy_pt_objects import (\n",
    "    GenerationMixin,\n",
    "    PreTrainedModel,\n",
    ")\n",
    "\n",
    "\n",
    "class CausallLM(PreTrainedModel, GenerationMixin):\n",
    "    pass\n",
    "\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "is_moe = False\n",
    "model, tokenizer = cast(\n",
    "    tuple[CausallLM, PreTrainedTokenizerBase],\n",
    "    (unsloth.FastModel if is_moe else unsloth.FastLanguageModel).from_pretrained(\n",
    "        model_name=model_id,\n",
    "        load_in_4bit=False,\n",
    "        max_seq_length=32768,  # Qwen2.5 supports up to 32k context\n",
    "    ),\n",
    ")\n",
    "peft_model = cast(\n",
    "    peft.peft_model.PeftModelForCausalLM,\n",
    "    unsloth.FastModel.get_peft_model(\n",
    "        model,\n",
    "        lora_alpha=16,\n",
    "        r=8,\n",
    "        random_state=3407,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "        + ([\"gate_proj\", \"up_proj\", \"down_proj\"] if not is_moe else []),\n",
    "    ),\n",
    ")\n",
    "lora_model = cast(peft.tuners.lora.LoraModel, peft_model.base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"./lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from safetensors.torch import load_file, save_file\n",
    "\n",
    "\n",
    "async def copy_lora_add_noise_and_log(\n",
    "    source_dir: str = \"./lora\",\n",
    "    noise_std: float = 1e-4,\n",
    "    artifact_type: str = \"lora\",\n",
    "    run=None,\n",
    ") -> str:\n",
    "    \"\"\"Copy ./lora to /tmp, add Gaussian noise to adapter weights on CPU, save, and log as a W&B artifact.\n",
    "    Returns the destination directory path.\n",
    "    \"\"\"\n",
    "    dst = tempfile.mkdtemp(prefix=\"lora_\", dir=\"/tmp\")\n",
    "    print(f\"Copying {source_dir} -> {dst}\")\n",
    "    shutil.copytree(source_dir, dst, dirs_exist_ok=True)\n",
    "\n",
    "    safetensors_path = os.path.join(dst, \"adapter_model.safetensors\")\n",
    "    tensors = load_file(safetensors_path, device=\"cpu\")\n",
    "\n",
    "    num_noised = 0\n",
    "    total = 0\n",
    "    with torch.inference_mode():\n",
    "        for _, tensor in tensors.items():\n",
    "            total += tensor.numel()\n",
    "            if tensor.is_floating_point():\n",
    "                tensor.add_(torch.randn_like(tensor) * noise_std)\n",
    "                num_noised += tensor.numel()\n",
    "\n",
    "    save_file(tensors, safetensors_path)\n",
    "\n",
    "    run = run or wandb.run\n",
    "    if run is not None:\n",
    "        name = f\"lora-noised-{int(time.time())}\"\n",
    "        artifact = wandb.Artifact(\n",
    "            name=name,\n",
    "            type=artifact_type,\n",
    "            metadata={\n",
    "                \"noise_std\": float(noise_std),\n",
    "                \"wandb.base_model\": \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "            },\n",
    "            storage_region=\"coreweave-us\",\n",
    "        )\n",
    "        artifact.add_dir(dst)\n",
    "        run.log_artifact(artifact)\n",
    "        await asyncio.to_thread(artifact.wait)\n",
    "        print(\n",
    "            f\"Noised {num_noised}/{total} params; saved to {safetensors_path}; logged artifact '{name}'.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"Noised {num_noised}/{total} params; saved to {safetensors_path}; no active W&B run found.\"\n",
    "        )\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying ./lora -> /tmp/lora_tiswiiol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/tmp/lora_tiswiiol)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noised 34406400/34406400 params; saved to /tmp/lora_tiswiiol/adapter_model.safetensors; logged artifact 'lora-noised-1759796163'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/lora_tiswiiol'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await copy_lora_add_noise_and_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wandb', 'es', 'northern-paper-4')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = run.entity\n",
    "project = run.project\n",
    "name = run.name\n",
    "(entity, project, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-496685f6-1a6e-4027-8c20-250b3749612d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! It's nice to meet you. How can I assist you today?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1759796917, model='wandb-artifact:///wandb/es/lora-noised-1759796163:v0', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=33, total_tokens=50, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, kv_transfer_params=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await openai_client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}],\n",
    "    model=f\"wandb-artifact:///{entity}/{project}/lora-noised-1759796163:v0\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
